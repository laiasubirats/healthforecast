{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "['admission_source_id', 'encounter_id', 'patient_nbr', 'medical_specialty', 'payer_code', 'index', 'admission_type_id', 'discharge_disposition_id']\n",
      "df_2 (101766, 43)\n",
      "[]\n",
      "df_3 (101766, 43)\n",
      "df_4 (101766, 43)\n",
      "[[  0.   1.  70. ...,   1.   1.  31.]\n",
      " [  0.   1.  50. ...,   1.   1.   0.]\n",
      " [  0.   1.  70. ...,   1.   1.  31.]\n",
      " ..., \n",
      " [  0.   0.  80. ...,   1.   1.   0.]\n",
      " [  0.   1.  90. ...,   1.   1.   0.]\n",
      " [  0.   0.  80. ...,   0.   0.   0.]]\n",
      "indices [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 21 23 24 26 27 34\n",
      " 40 41 42]\n",
      "lenindex 28\n",
      "nateglinide\n",
      "chlorpropamide\n",
      "acetohexamide\n",
      "tolbutamide\n",
      "acarbose\n",
      "miglitol\n",
      "troglitazone\n",
      "tolazamide\n",
      "examide\n",
      "citoglipton\n",
      "glyburide-metformin\n",
      "glipizide-metformin\n",
      "glimepiride-pioglitazone\n",
      "metformin-rosiglitazone\n",
      "metformin-pioglitazone\n",
      "after (101766, 28)\n",
      "initial (101766, 43)\n",
      "Headers_FINAL:  ['race', 'gender', 'age', 'weight', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted']\n",
      "Columns high correlation time_in_hospital , num_medications 0.466135417431\n",
      "df.shape (81597, 28)\n",
      "df_test.shape (20169, 28)\n",
      "{0.0, 1.0}\n",
      "{0.0, 1.0}\n",
      "Test {0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import truediv\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy import stats\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_all=pd.read_csv('C:/diabetic_data_processed_withweight.csv',';')\n",
    "print(type(df_all))\n",
    "to_del = ['admission_source_id','encounter_id', 'patient_nbr','medical_specialty','payer_code','index','admission_type_id','discharge_disposition_id']        \n",
    "print (to_del)\n",
    "\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df_all.columns if (c not in to_del) ]#and ('ENF' not in c)\n",
    "df_2 = df_all[filtered_cols]\n",
    "print (\"df_2\",df_2.shape)\n",
    "\n",
    "# Filter complete null columns\n",
    "cols = np.where((np.sum(df_2.isnull(), axis=0).values) == df_2.shape[0])[0]\n",
    "print (cols)\n",
    "filt_cols = [c for c in df_2.columns if c not in df_2.columns[cols]]\n",
    "df_3 = df_2[filt_cols]\n",
    "print (\"df_3\",df_3.shape)\n",
    "\n",
    "#Fill na\n",
    "df_4 = df_3.fillna(value=np.mean(df_3,axis=0),inplace=False,axis=0).values\n",
    "print (\"df_4\",df_4.shape)\n",
    "data=df_4\n",
    "\n",
    "selector = VarianceThreshold(threshold=(.99 * (1 - .99)))\n",
    "newdata=selector.fit_transform(data)\n",
    "idxs = selector.get_support(indices=True)\n",
    "print(data[:, idxs])\n",
    "print(\"indices\",idxs)\n",
    "columnslist=df_3.columns.tolist()\n",
    "print(\"lenindex\",len(idxs))\n",
    "for z in range(0,len(columnslist)):\n",
    "    if z not in idxs:\n",
    "        print(columnslist[z])\n",
    "print(\"after\",newdata.shape)\n",
    "print(\"initial\",data.shape)\n",
    "print(\"Headers_FINAL: \", df_2.columns.values.tolist())\n",
    "for z in range(0,len(idxs)-1): \n",
    "    for y in range(0,len(idxs)-1): \n",
    "        #print(\"column: \",data[:,z])\n",
    "        if (z!=y and z<y):\n",
    "            correlation=stats.pearsonr(data[:,z], data[:,y])\n",
    "            if (abs(correlation[0])>0.4):\n",
    "                print(\"Columns high correlation\",df_3.columns[z],\",\",df_3.columns[y],correlation[0])\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(newdata)) < 0.8\n",
    "df, df_test = newdata[msk].copy(), newdata[~msk].copy()\n",
    "print(\"df.shape\",df.shape)\n",
    "print(\"df_test.shape\",df_test.shape)\n",
    "\n",
    "y_train=df[:,-1]\n",
    "y_test=df_test[:,-1]\n",
    "x_train=df[:,:-2]\n",
    "x_test=df_test[:,:-2]\n",
    "\n",
    "y_train=np.where(y_train > 0, 1, y_train)\n",
    "y_test=np.where(y_test > 0, 1, y_test)\n",
    "print(set(y_train))\n",
    "print(set(y_test))\n",
    "\n",
    "sm = SMOTE(n_jobs=-1, random_state=42,kind='regular')\n",
    "x_train_res,y_train_res = sm.fit_sample(x_train,y_train)\n",
    "x_test_res,y_test_res = sm.fit_sample(x_test,y_test)\n",
    "\n",
    "print(\"Test\", set(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_weighted\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.528 (+/-0.051) for {}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.54      0.87      0.67     10889\n",
      "        1.0       0.67      0.27      0.39     10889\n",
      "\n",
      "avg / total       0.61      0.57      0.53     21778\n",
      "\n",
      "Accuracy score:  0.569198273487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes\n",
    "#print (\"Reduced data: \",reduced_data.shape)\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "#'min_samples_leaf': [1,5,10,50,100,200,500],\n",
    "\n",
    "#tuned_parameters = {\n",
    "#    'n_estimators': [20, 50, 100],\n",
    "#    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#    'class_weight':['balanced']\n",
    "#}\n",
    "\n",
    "tuned_parameters = {  \n",
    "} \n",
    "\n",
    "#tuned_parameters = {  \n",
    "#    }  \n",
    "\n",
    "#scores = ['precision', 'recall', 'f1']\n",
    "#scores = [ 'f1_weighted','f1_micro','f1_macro','accuracy']\n",
    "scores=['f1_weighted']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    #clf = GridSearchCV(GaussianNB(), tuned_parameters, cv=10,scoring='%s_macro' % score)\n",
    "    #clf = GridSearchCV(estimator=rfc, param_grid=tuned_parameters, cv=5,scoring='%s_weighted' % score,n_jobs= -1)\n",
    "    #clf = GridSearchCV(estimator=rfc, param_grid=tuned_parameters, cv=5,scoring='%s' % score,n_jobs= -1)\n",
    "    clf = GridSearchCV(GaussianNB(), tuned_parameters, cv=10,scoring='%s' % score)\n",
    "    clf.fit(x_train_res, y_train_res)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    #y_train, y_pred = y_test, clf.predict(x_test)\n",
    "    y_train2, y_pred = y_test_res, clf.predict(x_test_res)\n",
    "    print(classification_report(y_train2, y_pred))\n",
    "    print(\"Accuracy score: \", accuracy_score(y_test_res, y_pred))\n",
    "    print()\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(y_test_res, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_weighted\n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "race :  0.0241882310297\n",
      "gender :  0.020643707579\n",
      "age :  0.052479588799\n",
      "weight :  0.00680922415686\n",
      "time_in_hospital :  0.0643392282355\n",
      "num_lab_procedures :  0.104415885048\n",
      "num_procedures :  0.0416676149131\n",
      "num_medications :  0.0901038735727\n",
      "number_outpatient :  0.023587220699\n",
      "number_emergency :  0.0197239372453\n",
      "number_inpatient :  0.0658351010265\n",
      "diag_1 :  0.0984159201308\n",
      "diag_2 :  0.0972703003043\n",
      "diag_3 :  0.095723000395\n",
      "number_diagnoses :  0.0463559683863\n",
      "max_glu_serum :  0.00916365360475\n",
      "A1Cresult :  0.0192342465665\n",
      "metformin :  0.0165803762519\n",
      "repaglinide :  0.00335816819809\n",
      "nateglinide :  0.00821738507371\n",
      "chlorpropamide :  0.0137436649354\n",
      "glimepiride :  0.0128115180501\n",
      "acetohexamide :  0.0093805656338\n",
      "glipizide :  0.00842563604051\n",
      "glyburide :  0.0296928240221\n",
      "tolbutamide :  0.0178331601022\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'class_weight': None, 'max_features': 'log2', 'n_estimators': 700}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.628 (+/-0.128) for {'class_weight': 'balanced', 'max_features': 'auto', 'n_estimators': 300}\n",
      "0.627 (+/-0.129) for {'class_weight': 'balanced', 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.627 (+/-0.128) for {'class_weight': 'balanced', 'max_features': 'auto', 'n_estimators': 700}\n",
      "0.627 (+/-0.127) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 300}\n",
      "0.627 (+/-0.128) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.628 (+/-0.128) for {'class_weight': 'balanced', 'max_features': 'sqrt', 'n_estimators': 700}\n",
      "0.627 (+/-0.128) for {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 300}\n",
      "0.627 (+/-0.128) for {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.628 (+/-0.127) for {'class_weight': 'balanced', 'max_features': 'log2', 'n_estimators': 700}\n",
      "0.627 (+/-0.129) for {'class_weight': None, 'max_features': 'auto', 'n_estimators': 300}\n",
      "0.627 (+/-0.128) for {'class_weight': None, 'max_features': 'auto', 'n_estimators': 500}\n",
      "0.628 (+/-0.129) for {'class_weight': None, 'max_features': 'auto', 'n_estimators': 700}\n",
      "0.628 (+/-0.127) for {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 300}\n",
      "0.628 (+/-0.127) for {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "0.628 (+/-0.127) for {'class_weight': None, 'max_features': 'sqrt', 'n_estimators': 700}\n",
      "0.627 (+/-0.129) for {'class_weight': None, 'max_features': 'log2', 'n_estimators': 300}\n",
      "0.630 (+/-0.131) for {'class_weight': None, 'max_features': 'log2', 'n_estimators': 500}\n",
      "0.630 (+/-0.129) for {'class_weight': None, 'max_features': 'log2', 'n_estimators': 700}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.73      0.68     10887\n",
      "        1.0       0.68      0.58      0.63     10887\n",
      "\n",
      "avg / total       0.66      0.65      0.65     21774\n",
      "\n",
      "Accuracy score:  0.654358409112\n",
      "\n",
      "i:  0 , specificity:  0.703244595452\n",
      "i:  1 , specificity:  0.731766509133\n",
      "SpecificityGlobal:  0.717505552293\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "#Decision tree\n",
    "#print (\"Reduced data: \",reduced_data.shape)\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=2, oob_score = True) \n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "#'min_samples_leaf': [1,5,10,50,100,200,500],\n",
    "\n",
    "tuned_parameters = {\n",
    "    'n_estimators': [300,500,700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'class_weight':['balanced',None]\n",
    "}\n",
    "\n",
    "#tuned_parameters = {  \n",
    "#    }  \n",
    "\n",
    "#scores = ['precision', 'recall', 'f1']\n",
    "#scores = [ 'f1_weighted','f1_micro','f1_macro','accuracy','roc_auc']\n",
    "scores=['f1_weighted']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    #clf = GridSearchCV(GaussianNB(), tuned_parameters, cv=10,scoring='%s_macro' % score)\n",
    "    #clf = GridSearchCV(estimator=rfc, param_grid=tuned_parameters, cv=5,scoring='%s_weighted' % score,n_jobs= -1)\n",
    "    clf = GridSearchCV(estimator=rfc, param_grid=tuned_parameters, cv=10,scoring='%s' % score,n_jobs= -1)\n",
    "    clf.fit(x_train_res, y_train_res)\n",
    "\n",
    "    \n",
    "    \n",
    "    array=clf.best_estimator_.feature_importances_\n",
    "    print(type(array))\n",
    "    for i in range (0,len(array)):\n",
    "        print(df_2.columns[i],\": \",array[i])\n",
    "    #print(\"clf: \",type(clf))\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    #y_train, y_pred = y_test, clf.predict(x_test)\n",
    "    y_train2, y_pred = y_test_res, clf.predict(x_test_res)\n",
    "    print(classification_report(y_train2, y_pred))\n",
    "    print(\"Accuracy score: \", accuracy_score(y_test_res, y_pred))\n",
    "    print()\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(y_test_res, y_pred)\n",
    "    Total=0\n",
    "    for i in range(0,2): \n",
    "        Total=Total+cm[i,0]+cm[i,1]\n",
    "    specificity = [0,0]\n",
    "    for i in range(0,2): \n",
    "        TP=cm[i,i] \n",
    "        TN=Total-cm[i,0]-cm[i,1]+cm[i,i]\n",
    "        FP=cm[0,i]+cm[1,i]-cm[i,i]\n",
    "        FN=cm[i,0]+cm[i,1]-cm[i,i]\n",
    "        specificity[i]=(TN/(TN+TP))\n",
    "        print(\"i: \",i, \", specificity: \",specificity[i])\n",
    "    #accuracy= (TP+TN)/Total\n",
    "    #print(\"Accuracy: \",accuracy)\n",
    "    w = [0,0,0,0]\n",
    "    SpecificityGlobal=0\n",
    "    for i in range(0,2): \n",
    "        w[i]= (cm[i,0]+cm[i,1])/Total\n",
    "        SpecificityGlobal  =  SpecificityGlobal+ w[i] * specificity[i]\n",
    "    print(\"SpecificityGlobal: \", SpecificityGlobal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf','linear'], 'gamma': [1e-1,1e-3],\n",
    "                     'C': [1, 10, 100]}]\n",
    "\n",
    "#tuned_parameters = [{'kernel': ['rbf'],\n",
    "#                     'C': [1]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=10,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(x_train_res, y_train_res)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    #y_train, y_pred = y_test, clf.predict(x_test)\n",
    "    y_train2, y_pred = y_test_res, clf.predict(x_test_res)\n",
    "    print(classification_report(y_train2, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
