{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "['encounter_id', 'patient_nbr', 'medical_specialty', 'payer_code']\n",
      "df_2 (101766, 46)\n",
      "Index(['race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
      "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import truediv\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "get_ipython().magic('matplotlib')\n",
    "\n",
    "df=pd.read_csv('C:/diabetic_data_processed_withweight.csv',';')\n",
    "to_del = ['encounter_id', 'patient_nbr','medical_specialty','payer_code']\n",
    "print (to_del)\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df.columns if (c not in to_del) ]#and ('ENF' not in c)\n",
    "df_2 = df[filtered_cols]\n",
    "print (\"df_2\",df_2.shape)\n",
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if ((df_2.loc[i,'diag_1']==410 or df_2.loc[i,'diag_1']==412) or (df_2.loc[i,'diag_2']==410 or df_2.loc[i,'diag_2']==412) or (df_2.loc[i,'diag_3']==410 or df_2.loc[i,'diag_3']==412)):\n",
    "        #print(df_2['diag_1'],df_2['diag_2'],df_2['diag_3'])\n",
    "        df_2.loc[i,'Myocardial_infarction']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Myocardial_infarction']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    96985\n",
      "1.0     4781\n",
      "Name: Myocardial_infarction, dtype: int64\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "17018 4781 4781 84748\n",
      "1028 1028 3753 3753\n",
      "Weight--> RR:  1.0 , RD:  0.0 , OR:  0.2739142019717559\n",
      "Age (74.080736247646939, 73.703162351840874, 74.458310143453005)\n",
      "Gender 0.0    2645\n",
      "1.0    2136\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    3937\n",
      "1.0     533\n",
      "2.0      98\n",
      "3.0      68\n",
      "4.0      24\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     2856\n",
      "31.0    1432\n",
      "29.0     493\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Myocardial_infarction'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Myocardial_infarction']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Myocardial_infarction']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listMI=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Myocardial_infarction']==1):\n",
    "        listMI.append(df_2.loc[x,:])    \n",
    "df_MI = pd.DataFrame(listMI)\n",
    "df_MI['age'].describe()\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h\n",
    "print(\"Age\",mean_confidence_interval(df_MI['age']))\n",
    "print(\"Gender\",df_MI['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_MI['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_MI['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if (df_2.loc[i,'diag_1']==428 or df_2.loc[i,'diag_2']==428 or (df_2.loc[i,'diag_3']==428)):\n",
    "        #print(df_2['diag_1'],df_2['diag_2'],df_2['diag_3'])\n",
    "        df_2.loc[i,'Congestive_heart_failure']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Congestive_heart_failure']=0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    84302\n",
      "1    17464\n",
      "Name: Congestive_heart_failure, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 17464 17464 2378\n",
      "109 109 332 332\n",
      "Weight--> RR:  1.0 , RD:  0.0 , OR:  0.32831325301204817\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "17018 17464 17464 84748\n",
      "2712 2712 14752 14752\n",
      "A1CResult--> RR:  1.0 , RD:  0.0 , OR:  0.18383947939262474\n",
      "Age (77.187356848373796, 76.999992235787019, 77.374721460960572)\n",
      "Gender 1.0    9547\n",
      "0.0    7917\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    13273\n",
      "1.0     3351\n",
      "3.0      262\n",
      "2.0      186\n",
      "4.0       61\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     7809\n",
      "31.0    7365\n",
      "29.0    2290\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Congestive_heart_failure'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Congestive_heart_failure']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Congestive_heart_failure']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Congestive_heart_failure']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Congestive_heart_failure']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Congestive_heart_failure']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "df_CHF['age'].describe()\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if (df_2.loc[i,'diag_1'] in (443,441,785,43) \n",
    "        or df_2.loc[i,'diag_2'] in (443,441,785,43)  \n",
    "        or df_2.loc[i,'diag_3'] in (443,441,785,43)):\n",
    "        df_2.loc[i,'Peripheral_vascular_disease']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Peripheral_vascular_disease']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    99851\n",
      "1     1915\n",
      "Name: Peripheral_vascular_disease, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 1915 1915 2378\n",
      "23 23 41 41\n",
      "Weight--> RR:  1.0 , RD:  0.0 , OR:  0.5609756097560976\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "17018 1915 1915 84748\n",
      "281 281 1634 1634\n",
      "A1CResult--> RR:  1.0 , RD:  0.0 , OR:  0.17197062423500611\n",
      "Age (72.44908616187989, 71.828490629770698, 73.069681693989082)\n",
      "Gender 0.0    1005\n",
      "1.0     910\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    1478\n",
      "1.0     318\n",
      "3.0      36\n",
      "2.0      29\n",
      "4.0       7\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     1040\n",
      "31.0     619\n",
      "29.0     256\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Peripheral_vascular_disease'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Peripheral_vascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Peripheral_vascular_disease']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Peripheral_vascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Peripheral_vascular_disease']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Peripheral_vascular_disease']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if ((df_2.loc[i,'diag_1']>=430 and df_2.loc[i,'diag_1']<=438) or (df_2.loc[i,'diag_2']>=430 and df_2.loc[i,'diag_2']<=438) or (df_2.loc[i,'diag_3']>=430 and df_2.loc[i,'diag_3']<=438)):\n",
    "        df_2.loc[i,'Cerebrovascular_disease']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Cerebrovascular_disease']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    96197\n",
      "1.0     5569\n",
      "Name: Cerebrovascular_disease, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 5569 5569 2378\n",
      "27 27 130 130\n",
      "Weight--> RR:  1.0 , RD:  0.0 , OR:  0.2076923076923077\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "17018 5569 5569 84748\n",
      "1132 1132 4437 4437\n",
      "A1CResult--> RR:  1.0 , RD:  0.0 , OR:  0.2551273382916385\n",
      "count    5569.000000\n",
      "mean       75.760460\n",
      "std        12.326413\n",
      "min        10.000000\n",
      "25%        70.000000\n",
      "50%        80.000000\n",
      "75%        80.000000\n",
      "max       100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (75.760459687556107, 75.436649424379453, 76.084269950732761)\n",
      "Gender 1.0    2961\n",
      "0.0    2608\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    3971\n",
      "1.0    1243\n",
      "3.0      97\n",
      "2.0      86\n",
      "4.0      52\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     3161\n",
      "31.0    1733\n",
      "29.0     675\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Cerebrovascular_disease'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Cerebrovascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Cerebrovascular_disease']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Cerebrovascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Cerebrovascular_disease']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Cerebrovascular_disease']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if (df_2.loc[i,'diag_1']==290 or df_2.loc[i,'diag_2']==290 or df_2.loc[i,'diag_3']==290):\n",
    "        df_2.loc[i,'Dementia']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Dementia']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    101555\n",
      "1.0       211\n",
      "Name: Dementia, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 211 211 2378\n",
      "0 0 4 4\n",
      "Weight--> OR:  0.0\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "17018 211 211 84748\n",
      "44 44 167 167\n",
      "A1CResult--> RR:  1.0 , RD:  0.0 , OR:  0.2634730538922156\n",
      "count    211.000000\n",
      "mean      83.459716\n",
      "std        9.898150\n",
      "min       50.000000\n",
      "25%       80.000000\n",
      "50%       90.000000\n",
      "75%       90.000000\n",
      "max      100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (83.459715639810426, 82.116421937900355, 84.803009341720497)\n",
      "Gender 1.0    122\n",
      "0.0     89\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    159\n",
      "1.0     41\n",
      "2.0      5\n",
      "3.0      2\n",
      "4.0      1\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     142\n",
      "31.0     49\n",
      "29.0     20\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Dementia'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Dementia']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Dementia']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "#RR=(a/(a+b)) / (c/(c+d))\n",
    "#RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Dementia']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Dementia']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Dementia']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if ((df_2.loc[i,'diag_1']>=490 and df_2.loc[i,'diag_1']<=506) or (df_2.loc[i,'diag_2']>=490 and df_2.loc[i,'diag_2']<=506) or (df_2.loc[i,'diag_3']>=490 and df_2.loc[i,'diag_3']<=506)):\n",
    "        df_2.loc[i,'Chronic_pulmonary_disease']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Chronic_pulmonary_disease']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    88126\n",
      "1.0    13640\n",
      "Name: Chronic_pulmonary_disease, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 13640 13640 2378\n",
      "92 92 233 233\n",
      "Weight--> RR:  1.0 , RD:  0.0 , OR:  0.3948497854077253\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "17018 13640 13640 84748\n",
      "2238 2238 11402 11402\n",
      "A1CResult--> RR:  1.0 , RD:  0.0 , OR:  0.196281354148395\n",
      "count    13640.000000\n",
      "mean        73.488270\n",
      "std         13.325404\n",
      "min         10.000000\n",
      "25%         70.000000\n",
      "50%         70.000000\n",
      "75%         80.000000\n",
      "max        100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (73.488269794721404, 73.264624460374989, 73.711915129067819)\n",
      "Gender 1.0    7518\n",
      "0.0    6122\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    11090\n",
      "1.0     1827\n",
      "3.0      242\n",
      "2.0      149\n",
      "4.0       54\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     6323\n",
      "31.0    5732\n",
      "29.0    1585\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Chronic_pulmonary_disease'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Chronic_pulmonary_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Chronic_pulmonary_disease']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Chronic_pulmonary_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Chronic_pulmonary_disease']==1\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Chronic_pulmonary_disease']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
      "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
      "       'Chronic_pulmonary_disease', 'Myocardial_infarction',\n",
      "       'Congestive_heart_failure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diag_1', 'diag_2', 'diag_3']\n",
      "df_3 (101766, 49)\n",
      "Index(['race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
      "       'Chronic_pulmonary_disease', 'Myocardial_infarction',\n",
      "       'Congestive_heart_failure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "to_del2 = ['diag_1', 'diag_2','diag_3']\n",
    "print (to_del2)\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df_2.columns if (c not in to_del2) ]#and ('ENF' not in c)\n",
    "df_3 = df_2[filtered_cols]\n",
    "print (\"df_3\",df_3.shape)\n",
    "print(df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 49)\n",
      "df.shape (81306, 50)\n",
      "df_test.shape (20460, 50)\n",
      "{0, 29, 31}\n",
      "{0, 29, 31}\n",
      "{'miglitol', 'num_lab_procedures', 'insulin', 'weight', 'metformin-rosiglitazone', 'repaglinide', 'rosiglitazone', 'nateglinide', 'age', 'discharge_disposition_id', 'num_procedures', 'A1Cresult', 'readmitted', 'number_diagnoses', 'time_in_hospital', 'Cerebrovascular_disease', 'tolbutamide', 'Dementia', 'number_emergency', 'examide', 'Congestive_heart_failure', 'acarbose', 'citoglipton', 'glyburide-metformin', 'max_glu_serum', 'num_medications', 'chlorpropamide', 'admission_type_id', 'Peripheral_vascular_disease', 'race', 'glyburide', 'metformin-pioglitazone', 'admission_source_id', 'Chronic_pulmonary_disease', 'number_inpatient', 'glimepiride', 'number_outpatient', 'metformin', 'gender', 'glipizide', 'troglitazone', 'glipizide-metformin', 'pioglitazone', 'acetohexamide', 'change', 'tolazamide', 'glimepiride-pioglitazone', 'diabetesMed', 'Myocardial_infarction'}\n",
      "{'miglitol', 'num_lab_procedures', 'insulin', 'weight', 'metformin-rosiglitazone', 'repaglinide', 'rosiglitazone', 'nateglinide', 'age', 'discharge_disposition_id', 'num_procedures', 'A1Cresult', 'readmitted', 'number_diagnoses', 'time_in_hospital', 'Cerebrovascular_disease', 'tolbutamide', 'Dementia', 'number_emergency', 'examide', 'Congestive_heart_failure', 'acarbose', 'citoglipton', 'glyburide-metformin', 'max_glu_serum', 'num_medications', 'chlorpropamide', 'admission_type_id', 'Peripheral_vascular_disease', 'race', 'glyburide', 'metformin-pioglitazone', 'admission_source_id', 'Chronic_pulmonary_disease', 'number_inpatient', 'glimepiride', 'number_outpatient', 'metformin', 'gender', 'glipizide', 'troglitazone', 'glipizide-metformin', 'pioglitazone', 'acetohexamide', 'change', 'tolazamide', 'glimepiride-pioglitazone', 'diabetesMed', 'Myocardial_infarction'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "mid = df_3['readmitted']\n",
    "df_3.drop(labels=['readmitted'], axis=1,inplace = True)\n",
    "df_3.insert(0, 'readmitted', mid)\n",
    "print(df_3.shape)\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(df_3)) < 0.8\n",
    "df, df_test = df_3[msk].copy(deep = True), df_3[~msk].copy(deep = True)\n",
    "df = df.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "print(\"df.shape\",df.shape)\n",
    "print(\"df_test.shape\",df_test.shape)\n",
    "y_train=df['readmitted']\n",
    "y_test=df_test['readmitted']\n",
    "print(set(y_train))\n",
    "print(set(y_test))\n",
    "\n",
    "x_train=df.iloc[:,1:50]\n",
    "x_test=df_test.iloc[:,1:50]\n",
    "print(set(x_train))\n",
    "print(set(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['readmitted', 'race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed',\n",
      "       'Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
      "       'Chronic_pulmonary_disease', 'Myocardial_infarction',\n",
      "       'Congestive_heart_failure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_4 (101766, 49)\n",
      "data (101766, 49)\n"
     ]
    }
   ],
   "source": [
    "#Fill na\n",
    "df_4 = df_3.fillna(value=np.mean(df_3,axis=0),inplace=False,axis=0).values\n",
    "print (\"df_4\",df_4.shape)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(df_4)\n",
    "data = scaler.transform(df_4)\n",
    "print (\"data\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num pca_comps per > 0.8 ratio: 11 0.808905325842\n",
      "Explained variance first 2 components 0.339700396065\n",
      "49\n",
      "0.339700396065\n",
      "PCA+K-means: 11\n"
     ]
    }
   ],
   "source": [
    "#### Feat sel with pca(0.8, 0.9) explained var \n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "newdata, newdata_test = data[msk].copy(), data[~msk].copy()\n",
    "\n",
    "data=newdata\n",
    "\n",
    "thrd = 0.8\n",
    "total = 0\n",
    "pca = PCA().fit(data)\n",
    "reduced_data = pca.transform(data)\n",
    "for pca_comps,r in enumerate(pca.explained_variance_ratio_):\n",
    "    if total > thrd:\n",
    "        break\n",
    "    total += r\n",
    "print (\"Num pca_comps per >\", thrd,\"ratio:\", pca_comps, total)\n",
    "print (\"Explained variance first 2 components\",pca.explained_variance_ratio_[0]+pca.explained_variance_ratio_[1])\n",
    "print (pca.n_components_)\n",
    "print (np.sum(pca.explained_variance_ratio_[:2]))\n",
    "\n",
    "print (\"PCA+K-means:\", pca_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2  the average metrics.calinski_harabaz_score is : 22650.8106865\n",
      "For n_clusters = 3  the average metrics.calinski_harabaz_score is : 18818.0893855\n",
      "For n_clusters = 4  the average metrics.calinski_harabaz_score is : 17973.1714991\n",
      "For n_clusters = 5  the average metrics.calinski_harabaz_score is : 16869.4599806\n",
      "For n_clusters = 6  the average metrics.calinski_harabaz_score is : 15269.6169899\n",
      "For n_clusters = 7  the average metrics.calinski_harabaz_score is : 14867.5171957\n",
      "For n_clusters = 8  the average metrics.calinski_harabaz_score is : 13801.2201756\n",
      "For n_clusters = 9  the average metrics.calinski_harabaz_score is : 13417.937195\n",
      "For n_clusters = 10  the average metrics.calinski_harabaz_score is : 13132.8078569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "for k in [2,3,4,5,6,7,8,9,10]:\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(reduced_data[:,:pca_comps])\n",
    "    #cluster_labels=kmeans.fit(reduced_data[:,:2])\n",
    "    #silhouette_avg = silhouette_score(reduced_data[:,:pca_comps], cluster_labels)\n",
    "    #silhouette_avg = silhouette_score(reduced_data[:,:2], cluster_labels)\n",
    "    #print(\"For n_clusters =\", k, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    calinski_harabaz_score_avg = metrics.calinski_harabaz_score(reduced_data[:,:pca_comps], cluster_labels)\n",
    "    #calinski_harabaz_score_avg = metrics.calinski_harabaz_score(reduced_data[:,:2], cluster_labels)\n",
    "    print(\"For n_clusters =\", k,\" the average metrics.calinski_harabaz_score is :\", calinski_harabaz_score_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "pca = PCA().fit(data)\n",
    "cluster_labels = kmeans.fit_predict(reduced_data[:,:2])\n",
    "plt.figure()\n",
    "plt.plot(range(len(pca.explained_variance_ratio_)), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.axvline(pca_comps, color=\"red\")  \n",
    "plt.ylim(0.0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_data = pca.transform(data)\n",
    "#print (\"Reduced data: \",reduced_data.shape)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(reduced_data[:,:2])\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min()-.05, reduced_data[:, 0].max()+.05\n",
    "y_min, y_max = reduced_data[:, 1].min()-.05, reduced_data[:, 1].max()+.05\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(10,10))\n",
    "#plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap= plt.cm.Pastel2,#cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "#plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=4)\n",
    "\n",
    "#listA=df[df['readmitted'] == 0].index\n",
    "#plt.plot(reduced_data[listA, 0], reduced_data[listA, 1],'k.', markersize=4, c='g', label='No Readmitted')\n",
    "#listB=df[df['readmitted'] == 29].index\n",
    "#plt.plot(reduced_data[listB, 0],reduced_data[listB, 1],'k.', markersize=4, c='r',label ='<30')\n",
    "#listC=df[df['readmitted'] == 31].index\n",
    "#plt.plot(reduced_data[listC, 0],reduced_data[listC, 1],'k.', markersize=4, c='b',label ='>30')\n",
    "\n",
    "listA=df[df['Congestive_heart_failure'] == 0].index\n",
    "plt.plot(reduced_data[listA, 0], reduced_data[listA, 1],'k.', markersize=4, c='g', label='No disease')\n",
    "listB=df[df['Congestive_heart_failure'] == 1].index\n",
    "plt.plot(reduced_data[listB, 0],reduced_data[listB, 1],'k.', markersize=4, c='r',label ='Disease')\n",
    "\n",
    "#Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
    "#       'Chronic_pulmonary_disease', 'Myocardial_infarction',\n",
    "#       'Congestive_heart_failure'\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[0, 0], centroids[0, 1],\n",
    "            marker='>', s=169, linewidths=3, \n",
    "            color='black', zorder=10)\n",
    "plt.scatter(centroids[1, 0], centroids[1, 1],\n",
    "            marker='H', s=169, linewidths=3, \n",
    "            color='black', zorder=10)\n",
    "plt.title('K-means clustering on the diabetes dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_diabetes =  [35744, 41736]\n",
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_Peripheral_vascular_disease =  [36825, 42947]\n",
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_Cerebrovascular_disease =  [35385, 41460]\n",
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_Dementia =  [37483, 43663]\n",
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_Chronic_pulmonary_disease =  [32129, 38209]\n",
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_Congestive_heart_failure =  [31014, 36294]\n",
      "cluster_sizes =  [37545, 43763]\n",
      "num_no_readmitted =  [19316, 24473]\n",
      "average age =  [70.801438274071117, 70.581541484815943]\n",
      "average weight =  [92.670186504916401, 92.530952454142053]\n"
     ]
    }
   ],
   "source": [
    "num_Myocardial_infarction = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Myocardial_infarction\")] == 0):\n",
    "        num_Myocardial_infarction[cluster_labels[i]] = num_Myocardial_infarction[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_diabetes = \", num_Myocardial_infarction)\n",
    "\n",
    "num_Peripheral_vascular_disease = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Peripheral_vascular_disease\")] == 0):\n",
    "        num_Peripheral_vascular_disease[cluster_labels[i]] = num_Peripheral_vascular_disease[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Peripheral_vascular_disease = \", num_Peripheral_vascular_disease)\n",
    "\n",
    "num_Cerebrovascular_disease = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Cerebrovascular_disease\")] == 0):\n",
    "        num_Cerebrovascular_disease[cluster_labels[i]] = num_Cerebrovascular_disease[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Cerebrovascular_disease = \", num_Cerebrovascular_disease)\n",
    "\n",
    "num_Dementia = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Dementia\")] == 0):\n",
    "        num_Dementia[cluster_labels[i]] = num_Dementia[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Dementia = \", num_Dementia)\n",
    "\n",
    "num_Chronic_pulmonary_disease = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Chronic_pulmonary_disease\")] == 0):\n",
    "        num_Chronic_pulmonary_disease[cluster_labels[i]] = num_Chronic_pulmonary_disease[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Chronic_pulmonary_disease = \", num_Chronic_pulmonary_disease)\n",
    "\n",
    "num_Congestive_heart_failure = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Congestive_heart_failure\")] == 0):\n",
    "        num_Congestive_heart_failure[cluster_labels[i]] = num_Congestive_heart_failure[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Congestive_heart_failure = \", num_Congestive_heart_failure)\n",
    "\n",
    "num_readmitted = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"readmitted\")] == 0):\n",
    "        num_readmitted[cluster_labels[i]] = num_readmitted[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_readmitted = \", num_readmitted)\n",
    "\n",
    "num_age = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "        num_age[cluster_labels[i]] = num_age[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(\"age\")]\n",
    "mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "print (\"average age = \", list(map(truediv,num_age,mida_cluster)))\n",
    "\n",
    "num_age = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "        num_age[cluster_labels[i]] = num_age[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(\"weight\")]\n",
    "mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "print (\"average weight = \", list(map(truediv,num_age,mida_cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20458, 49)\n",
      "(81308, 49)\n",
      "Confusion matrix, without normalization\n",
      "[[10992     0]\n",
      " [    0  9466]]\n",
      "Normalized confusion matrix\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "Accuracy score 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   cluster0       1.00      1.00      1.00     10992\n",
      "   cluster1       1.00      1.00      1.00      9466\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20458\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'max_depth': None, 'criterion': 'gini', 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "print(newdata_test.shape)\n",
    "print(newdata.shape)\n",
    "pca_test = PCA().fit(newdata_test)\n",
    "reduced_data_test = pca_test.transform(newdata_test)\n",
    "pca = PCA().fit(newdata)\n",
    "reduced_data = pca_test.transform(newdata)\n",
    "n_clusters=2\n",
    "pca_comps=11\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(reduced_data[:,:pca_comps])\n",
    "y_train=kmeans.labels_\n",
    "y_test=kmeans.predict(reduced_data_test[:,:pca_comps])\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "#              \"min_samples_split\": [2, 10, 20],\n",
    "#              \"max_depth\": [None, 2, 5, 10],\n",
    "#              \"min_samples_leaf\": [1, 5, 10],\n",
    "#              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "#              }\n",
    "\n",
    "param_grid = {\"criterion\": [\"gini\"],\n",
    "              \"min_samples_split\": [2],\n",
    "              \"max_depth\": [None],\n",
    "              \"min_samples_leaf\": [5],\n",
    "              \"max_leaf_nodes\": [5],\n",
    "              }\n",
    "\n",
    "tree2 = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid)\n",
    "\n",
    "tree2.fit(reduced_data, y_train)\n",
    "y_pred = tree2.predict(reduced_data_test)\n",
    "\n",
    "#max_depth=4\n",
    "#clf = tree.DecisionTreeClassifier(random_state=13)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, kmeans.labels_, test_size=0.2)\n",
    "#y_pred = clf.fit(df_4, y_train).predict(df_4_test)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names=['cluster0','cluster1']\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score\", accuracy_score(y_test, y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(tree2.best_params_)\n",
    "    \n",
    "with open(\"C://Users/laia.subirats/Documents/output_diabetes.dot\", \"w\") as output_file:\n",
    "    tree.export_graphviz(tree2.best_estimator_, out_file=output_file, feature_names=df_3.columns.tolist(),class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 101766 but corresponding boolean dimension is 81308\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 101766 but corresponding boolean dimension is 81308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admission_source_id :  [5.9320887507711992, 5.7227593554401386] , p-value:  3.25032009654e-12\n",
      "discharge_disposition_id :  [3.9795717843840688, 3.7993874017845251] , p-value:  3.55847344377e-06\n",
      "change :  [0.44076045974910311, 0.45691836462911173] , p-value:  3.8572986985e-06\n",
      "glyburide-metformin :  [0.0051641797865777028, 0.0076441603409242243] , p-value:  2.22039940658e-05\n",
      "num_lab_procedures :  [43.628430409249823, 43.088693567718735] , p-value:  6.50845410439e-05\n",
      "weight :  [92.530952454142053, 92.670186504916401] , p-value:  8.83913055025e-05\n",
      "number_emergency :  [0.16413408587162673, 0.18500466107337862] , p-value:  0.000116787176983\n",
      "glyburide :  [0.10659689692205744, 0.096577440404847517] , p-value:  0.000179015885585\n",
      "number_diagnoses :  [7.2297145990905562, 7.2772672792648825] , p-value:  0.000590839824494\n",
      "pioglitazone :  [0.064986404039942422, 0.071194566520175792] , p-value:  0.00128522165858\n",
      "max_glu_serum :  [7.379452962548271, 6.4221334398721535] , p-value:  0.00211068396078\n",
      "num_procedures :  [1.3511642254872838, 1.3200159808230123] , p-value:  0.00860654799598\n",
      "acarbose :  [0.0026049402463268058, 0.003595685177786656] , p-value:  0.0176100073167\n",
      "insulin :  [0.26906290702191349, 0.28618990544679718] , p-value:  0.0189394614538\n",
      "diabetesMed :  [0.75991134063021271, 0.7667598881342389] , p-value:  0.022040756654\n"
     ]
    }
   ],
   "source": [
    "#P-values of attributes of each cluster\n",
    "import scipy.stats as stats\n",
    "#true_mu = 0\n",
    "listaA=df_3.columns.tolist()\n",
    "cluster1=df_4[kmeans.labels_==0]\n",
    "cluster2=df_4[kmeans.labels_==1]\n",
    "cluster_labels=kmeans.labels_\n",
    "#print(cluster1.shape)\n",
    "#print(cluster2.shape)\n",
    "contador=0\n",
    "for z in range(0,len(df_3.columns.tolist())):\n",
    "    two_sample = stats.ttest_ind(cluster1[:,z],cluster2[:,z])\n",
    "    if(two_sample[1]<0.05):contador=contador+1\n",
    "\n",
    "w, h = 3, contador\n",
    "Matrix = [[0.0 for x in range(w)] for y in range(h)] \n",
    "i=0\n",
    "for z in range(0,len(df_3.columns.tolist())):\n",
    "    #print(df_2.loc[1,z])\n",
    "    #print(np.std(cluster1[:,z]))\n",
    "    #print(df_2.values[:,z])\n",
    "    two_sample = stats.ttest_ind(cluster1[:,z],cluster2[:,z])\n",
    "    #two_sample = stats.chisquare(cluster1[:,8],cluster2[:,8])\n",
    "    if(two_sample[1]<0.05): \n",
    "        #print(i)\n",
    "        Matrix[i][0]=listaA[z]\n",
    "        Matrix[i][1]='{0:.400f}'.format(two_sample[1])\n",
    "        Matrix[i][2]=two_sample[1]\n",
    "        i=i+1\n",
    "arr = np.array(Matrix)\n",
    "arr = arr[arr[:,1].argsort()]\n",
    "#print(arr)\n",
    "\n",
    "for z in range(0,h):\n",
    "    if (0<1):\n",
    "        num_hipertensos = [0] * n_clusters\n",
    "        for i in range(len(data[:,:2])):\n",
    "            num_hipertensos[cluster_labels[i]] = num_hipertensos[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(arr[z,0])]\n",
    "        mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "        print ((arr[z,0]),\": \", list(map(truediv,num_hipertensos,mida_cluster)),\", p-value: \",arr[z,2])\n",
    "    else:\n",
    "        num_hipertensos = [0] * n_clusters\n",
    "        for i in range(len(data[:,:2])):\n",
    "            #print(\"z\",z)\n",
    "            #print(\"i\",i)\n",
    "            if (data[i][df_3.columns.get_loc(arr[z,0])] == 1):\n",
    "                num_hipertensos[cluster_labels[i]] = num_hipertensos[cluster_labels[i]] + 1\n",
    "        mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "        percentage=list(map(truediv,num_hipertensos,mida_cluster))\n",
    "        percentage[0]=round(percentage[0],2)\n",
    "        percentage[1]=round(percentage[1],2)\n",
    "        print ((arr[z,0]),\": \", num_hipertensos,\", percentage: \",percentage, \"p-value: \",arr[z,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
