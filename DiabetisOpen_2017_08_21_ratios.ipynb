{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "['encounter_id', 'patient_nbr', 'medical_specialty', 'payer_code']\n",
      "df_2 (101766, 46)\n",
      "Index(['race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
      "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import truediv\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "get_ipython().magic('matplotlib')\n",
    "\n",
    "df=pd.read_csv('C:/diabetic_data_processed_withweight.csv',';')\n",
    "to_del = ['encounter_id', 'patient_nbr','medical_specialty','payer_code']\n",
    "print (to_del)\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df.columns if (c not in to_del) ]#and ('ENF' not in c)\n",
    "df_2 = df[filtered_cols]\n",
    "print (\"df_2\",df_2.shape)\n",
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if ((df_2.loc[i,'diag_1']==410 or df_2.loc[i,'diag_1']==412) or (df_2.loc[i,'diag_2']==410 or df_2.loc[i,'diag_2']==412) or (df_2.loc[i,'diag_3']==410 or df_2.loc[i,'diag_3']==412)):\n",
    "        #print(df_2['diag_1'],df_2['diag_2'],df_2['diag_3'])\n",
    "        df_2.loc[i,'Myocardial_infarction']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Myocardial_infarction']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    96985\n",
      "1.0     4781\n",
      "Name: Myocardial_infarction, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 4781 96985 2378\n",
      "39 780 120 2258\n",
      "Weight--> RR:  0.9436507936507936 , RD:  -0.002843525972205538 , OR:  0.325\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "12028 4781 96985 89738\n",
      "769 11259 4012 85726\n",
      "A1Cresult--> RR:  1.430040647926523 , RD:  0.01922622611916034 , OR:  0.19167497507477568\n",
      "Age (74.080736247646939, 73.703162351840874, 74.458310143453005)\n",
      "Gender 0.0    2645\n",
      "1.0    2136\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    3937\n",
      "1.0     533\n",
      "2.0      98\n",
      "3.0      68\n",
      "4.0      24\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     2856\n",
      "31.0    1432\n",
      "29.0     493\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Myocardial_infarction'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Myocardial_infarction']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Myocardial_infarction']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "        \n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> 6.5\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< 6.5\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1Cresult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listMI=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Myocardial_infarction']==1):\n",
    "        listMI.append(df_2.loc[x,:])    \n",
    "df_MI = pd.DataFrame(listMI)\n",
    "df_MI['age'].describe()\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h\n",
    "print(\"Age\",mean_confidence_interval(df_MI['age']))\n",
    "print(\"Gender\",df_MI['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_MI['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_MI['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if (df_2.loc[i,'diag_1']==428 or df_2.loc[i,'diag_2']==428 or (df_2.loc[i,'diag_3']==428)):\n",
    "        #print(df_2['diag_1'],df_2['diag_2'],df_2['diag_3'])\n",
    "        df_2.loc[i,'Congestive_heart_failure']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Congestive_heart_failure']=0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    84302\n",
      "1.0    17464\n",
      "Name: Congestive_heart_failure, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 17464 84302 2378\n",
      "109 710 332 2046\n",
      "Weight--> RR:  0.9532709592950557 , RD:  -0.006523987180000634 , OR:  0.32831325301204817\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "12028 17464 84302 89738\n",
      "1857 10171 15607 74131\n",
      "A1CResult--> RR:  0.8877188463244675 , RD:  -0.019527646765183482 , OR:  0.1189850708015634\n",
      "Age (77.187356848373796, 76.999992235787019, 77.374721460960572)\n",
      "Gender 1.0    9547\n",
      "0.0    7917\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    13273\n",
      "1.0     3351\n",
      "3.0      262\n",
      "2.0      186\n",
      "4.0       61\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     7809\n",
      "31.0    7365\n",
      "29.0    2290\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Congestive_heart_failure'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Congestive_heart_failure']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Congestive_heart_failure']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Congestive_heart_failure']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Congestive_heart_failure']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> 6.5\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< 6.5\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Congestive_heart_failure']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "df_CHF['age'].describe()\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if (df_2.loc[i,'diag_1'] in (443,441,785,43) \n",
    "        or df_2.loc[i,'diag_2'] in (443,441,785,43)  \n",
    "        or df_2.loc[i,'diag_3'] in (443,441,785,43)):\n",
    "        df_2.loc[i,'Peripheral_vascular_disease']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Peripheral_vascular_disease']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    99851\n",
      "1.0     1915\n",
      "Name: Peripheral_vascular_disease, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 1915 99851 2378\n",
      "23 796 41 2337\n",
      "Weight--> RR:  1.6288156288156288 , RD:  0.010841648772683257 , OR:  0.5609756097560976\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "12028 1915 99851 89738\n",
      "202 11826 1713 88025\n",
      "A1CResult--> RR:  0.8797858509168429 , RD:  -0.0022947562613324125 , OR:  0.11792177466433158\n",
      "count    1915.000000\n",
      "mean       72.449086\n",
      "std        13.847463\n",
      "min        10.000000\n",
      "25%        60.000000\n",
      "50%        70.000000\n",
      "75%        80.000000\n",
      "max       100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (72.44908616187989, 71.828490629770698, 73.069681693989082)\n",
      "Gender 0.0    1005\n",
      "1.0     910\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    1478\n",
      "1.0     318\n",
      "3.0      36\n",
      "2.0      29\n",
      "4.0       7\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     1040\n",
      "31.0     619\n",
      "29.0     256\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Peripheral_vascular_disease'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Peripheral_vascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Peripheral_vascular_disease']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Peripheral_vascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Peripheral_vascular_disease']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> 6.5\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< 6.5\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Peripheral_vascular_disease']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if ((df_2.loc[i,'diag_1']>=430 and df_2.loc[i,'diag_1']<=438) or (df_2.loc[i,'diag_2']>=430 and df_2.loc[i,'diag_2']<=438) or (df_2.loc[i,'diag_3']>=430 and df_2.loc[i,'diag_3']<=438)):\n",
    "        df_2.loc[i,'Cerebrovascular_disease']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Cerebrovascular_disease']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    96197\n",
      "1.0     5569\n",
      "Name: Cerebrovascular_disease, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 5569 96197 2378\n",
      "27 792 130 2248\n",
      "Weight--> RR:  0.6030431107354185 , RD:  -0.021700755090157946 , OR:  0.2076923076923077\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "12028 5569 96197 89738\n",
      "793 11235 4776 84962\n",
      "A1CResult--> RR:  1.2387732992086027 , RD:  0.012707897178678887 , OR:  0.16603852596314908\n",
      "count    5569.000000\n",
      "mean       75.760460\n",
      "std        12.326413\n",
      "min        10.000000\n",
      "25%        70.000000\n",
      "50%        80.000000\n",
      "75%        80.000000\n",
      "max       100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (75.760459687556107, 75.436649424379453, 76.084269950732761)\n",
      "Gender 1.0    2961\n",
      "0.0    2608\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    3971\n",
      "1.0    1243\n",
      "3.0      97\n",
      "2.0      86\n",
      "4.0      52\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     3161\n",
      "31.0    1733\n",
      "29.0     675\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Cerebrovascular_disease'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Cerebrovascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Cerebrovascular_disease']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Cerebrovascular_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Cerebrovascular_disease']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> 6.5\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< 6.5\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Cerebrovascular_disease']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if (df_2.loc[i,'diag_1']==290 or df_2.loc[i,'diag_2']==290 or df_2.loc[i,'diag_3']==290):\n",
    "        df_2.loc[i,'Dementia']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Dementia']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    101555\n",
      "1.0       211\n",
      "Name: Dementia, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 211 101555 2378\n",
      "0 819 4 2374\n",
      "Weight--> RR:  1.1415367784822663 , RD:  0.00028863168849600773 , OR:  0.0\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "12028 211 101555 89738\n",
      "28 12000 183 89555\n",
      "A1CResult--> RR:  1.1415367784822663 , RD:  0.00028863168849600773 , OR:  0.15300546448087432\n",
      "count    211.000000\n",
      "mean      83.459716\n",
      "std        9.898150\n",
      "min       50.000000\n",
      "25%       80.000000\n",
      "50%       90.000000\n",
      "75%       90.000000\n",
      "max      100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (83.459715639810426, 82.116421937900355, 84.803009341720497)\n",
      "Gender 1.0    122\n",
      "0.0     89\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    159\n",
      "1.0     41\n",
      "2.0      5\n",
      "3.0      2\n",
      "4.0      1\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     142\n",
      "31.0     49\n",
      "29.0     20\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Dementia'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Dementia']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Dementia']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "#RR=(a/(a+b)) / (c/(c+d))\n",
    "#RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Dementia']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Dementia']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> 6.5\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< 6.5\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Dementia']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range (0,df_2['diag_3'].size):\n",
    "    if ((df_2.loc[i,'diag_1']>=490 and df_2.loc[i,'diag_1']<=506) or (df_2.loc[i,'diag_2']>=490 and df_2.loc[i,'diag_2']<=506) or (df_2.loc[i,'diag_3']>=490 and df_2.loc[i,'diag_3']<=506)):\n",
    "        df_2.loc[i,'Chronic_pulmonary_disease']=1\n",
    "    else:\n",
    "        df_2.loc[i,'Chronic_pulmonary_disease']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    88126\n",
      "1.0    13640\n",
      "Name: Chronic_pulmonary_disease, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3197.000000\n",
      "mean       92.595246\n",
      "std        25.465480\n",
      "min        25.000000\n",
      "25%              NaN\n",
      "50%              NaN\n",
      "75%              NaN\n",
      "max       201.000000\n",
      "Name: weight, dtype: float64\n",
      "mean 92.59524554269628\n",
      "819 13640 88126 2378\n",
      "92 727 233 2145\n",
      "Weight--> RR:  1.1464625026856787 , RD:  0.014350615275762466 , OR:  0.3948497854077253\n",
      "count    101766.000000\n",
      "mean          0.242537\n",
      "std           3.124083\n",
      "min          -1.000000\n",
      "25%          -1.000000\n",
      "50%          -1.000000\n",
      "75%          -1.000000\n",
      "max           9.000000\n",
      "Name: A1Cresult, dtype: float64\n",
      "mean 0.2425368001100564\n",
      "12028 13640 88126 89738\n",
      "1538 10490 12102 77636\n",
      "A1CResult--> RR:  0.94816114352689 , RD:  -0.006990949664997859 , OR:  0.12708643199471162\n",
      "count    13640.000000\n",
      "mean        73.488270\n",
      "std         13.325404\n",
      "min         10.000000\n",
      "25%         70.000000\n",
      "50%         70.000000\n",
      "75%         80.000000\n",
      "max        100.000000\n",
      "Name: age, dtype: float64\n",
      "Age (73.488269794721404, 73.264624460374989, 73.711915129067819)\n",
      "Gender 1.0    7518\n",
      "0.0    6122\n",
      "Name: gender, dtype: int64\n",
      "Race 0.0    11090\n",
      "1.0     1827\n",
      "3.0      242\n",
      "2.0      149\n",
      "4.0       54\n",
      "Name: race, dtype: int64\n",
      "Readmitted 0.0     6323\n",
      "31.0    5732\n",
      "29.0    1585\n",
      "Name: readmitted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_2['Chronic_pulmonary_disease'].astype('category').value_counts())\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Chronic_pulmonary_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Chronic_pulmonary_disease']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['weight'].describe())\n",
    "mean=df_2['weight'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'weight']> mean\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'weight']< mean\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"Weight-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "\n",
    "listA=[]\n",
    "listA1=[]\n",
    "listA=df_2.loc[:,'Chronic_pulmonary_disease']==1\n",
    "for x in range (0,len(listA)):\n",
    "    if(listA[x]==True):\n",
    "        listA1.append(x)\n",
    "listC=[]\n",
    "listC1=[]\n",
    "listC=df_2.loc[:,'Chronic_pulmonary_disease']==0\n",
    "for x in range (0,len(listC)):\n",
    "    if(listC[x]==True):\n",
    "        listC1.append(x)\n",
    "\n",
    "print(df_2['A1Cresult'].describe())\n",
    "mean=df_2['A1Cresult'].mean()\n",
    "print(\"mean\",mean)\n",
    "listB1=[]\n",
    "listB=df_2.loc[:,'A1Cresult']> 6.5\n",
    "listD1=[]\n",
    "listD=df_2.loc[:,'A1Cresult']< 6.5\n",
    "listD.describe()\n",
    "for x in range (0,len(listB)):\n",
    "    if(listB[x]==True):\n",
    "        listB1.append(x)\n",
    "for x in range (0,len(listD)):\n",
    "    if(listD[x]==True):\n",
    "        listD1.append(x)\n",
    "#No healty and bad social\n",
    "a=len(set(listB1).intersection(listA1))\n",
    "#Healthy and bad social\n",
    "b=len(set(listB1).intersection(listC1))\n",
    "#No healty and social\n",
    "c=len(set(listD1).intersection(listA1))\n",
    "#Healthy and social\n",
    "d=len(set(listD1).intersection(listC1))\n",
    "\n",
    "print(len(listB1), len(listA1), len(listC1),len(listD1))\n",
    "print(a,b,c,d)\n",
    "\n",
    "OR=(a*d)/(c*d)\n",
    "RR=(a/(a+b)) / (c/(c+d))\n",
    "RD=(a/(a+b)) - (c/(c+d))\n",
    "print(\"A1CResult-->\",\"RR: \",RR,\", RD: \",RD,\", OR: \",OR)\n",
    "#Characteristics\n",
    "listCHF=[]\n",
    "for x in range (0,len(df_2)):\n",
    "    if (df_2.loc[x,'Chronic_pulmonary_disease']==1):\n",
    "        listCHF.append(df_2.loc[x,:])    \n",
    "df_CHF = pd.DataFrame(listCHF)\n",
    "print(df_CHF['age'].describe())\n",
    "\n",
    "print(\"Age\",mean_confidence_interval(df_CHF['age']))\n",
    "print(\"Gender\",df_CHF['gender'].astype('category').value_counts())\n",
    "print(\"Race\",df_CHF['race'].astype('category').value_counts())\n",
    "print(\"Readmitted\",df_CHF['readmitted'].astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['race', 'gender', 'age', 'weight', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
      "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'Myocardial_infarction', 'Congestive_heart_failure',\n",
      "       'Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
      "       'Chronic_pulmonary_disease'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diag_1', 'diag_2', 'diag_3', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
      "df_3 (101766, 46)\n",
      "Index(['race', 'gender', 'age', 'weight', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'Myocardial_infarction', 'Congestive_heart_failure',\n",
      "       'Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
      "       'Chronic_pulmonary_disease'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "to_del2 = ['diag_1', 'diag_2','diag_3','admission_type_id','discharge_disposition_id','admission_source_id']\n",
    "print (to_del2)\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df_2.columns if (c not in to_del2) ]#and ('ENF' not in c)\n",
    "df_3 = df_2[filtered_cols]\n",
    "print (\"df_3\",df_3.shape)\n",
    "print(df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 46)\n",
      "df.shape (81313, 47)\n",
      "df_test.shape (20453, 47)\n",
      "{0, 29, 31}\n",
      "{0, 29, 31}\n",
      "{'insulin', 'weight', 'metformin-rosiglitazone', 'number_inpatient', 'number_emergency', 'tolbutamide', 'glyburide', 'number_diagnoses', 'A1Cresult', 'glyburide-metformin', 'citoglipton', 'time_in_hospital', 'examide', 'race', 'num_medications', 'glimepiride', 'readmitted', 'num_lab_procedures', 'Cerebrovascular_disease', 'repaglinide', 'miglitol', 'max_glu_serum', 'metformin', 'change', 'acarbose', 'num_procedures', 'glimepiride-pioglitazone', 'Chronic_pulmonary_disease', 'glipizide', 'nateglinide', 'rosiglitazone', 'metformin-pioglitazone', 'troglitazone', 'pioglitazone', 'number_outpatient', 'acetohexamide', 'age', 'Dementia', 'Peripheral_vascular_disease', 'Congestive_heart_failure', 'tolazamide', 'diabetesMed', 'glipizide-metformin', 'Myocardial_infarction', 'gender', 'chlorpropamide'}\n",
      "{'insulin', 'weight', 'metformin-rosiglitazone', 'number_inpatient', 'number_emergency', 'tolbutamide', 'glyburide', 'number_diagnoses', 'A1Cresult', 'glyburide-metformin', 'citoglipton', 'time_in_hospital', 'examide', 'race', 'num_medications', 'glimepiride', 'readmitted', 'num_lab_procedures', 'Cerebrovascular_disease', 'repaglinide', 'miglitol', 'max_glu_serum', 'metformin', 'change', 'acarbose', 'num_procedures', 'glimepiride-pioglitazone', 'Chronic_pulmonary_disease', 'glipizide', 'nateglinide', 'rosiglitazone', 'metformin-pioglitazone', 'troglitazone', 'pioglitazone', 'number_outpatient', 'acetohexamide', 'age', 'Dementia', 'Peripheral_vascular_disease', 'Congestive_heart_failure', 'tolazamide', 'diabetesMed', 'glipizide-metformin', 'Myocardial_infarction', 'gender', 'chlorpropamide'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "mid = df_3['readmitted']\n",
    "df_3.drop(labels=['readmitted'], axis=1,inplace = True)\n",
    "df_3.insert(0, 'readmitted', mid)\n",
    "print(df_3.shape)\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(df_3)) < 0.8\n",
    "df, df_test = df_3[msk].copy(deep = True), df_3[~msk].copy(deep = True)\n",
    "df = df.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "print(\"df.shape\",df.shape)\n",
    "print(\"df_test.shape\",df_test.shape)\n",
    "y_train=df['readmitted']\n",
    "y_test=df_test['readmitted']\n",
    "print(set(y_train))\n",
    "print(set(y_test))\n",
    "\n",
    "x_train=df.iloc[:,1:50]\n",
    "x_test=df_test.iloc[:,1:50]\n",
    "print(set(x_train))\n",
    "print(set(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['readmitted', 'race', 'gender', 'age', 'weight', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
      "       'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin',\n",
      "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
      "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed',\n",
      "       'Myocardial_infarction', 'Congestive_heart_failure',\n",
      "       'Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
      "       'Chronic_pulmonary_disease'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_4 (101766, 46)\n",
      "data (101766, 46)\n"
     ]
    }
   ],
   "source": [
    "#Fill na\n",
    "df_4 = df_3.fillna(value=np.mean(df_3,axis=0),inplace=False,axis=0).values\n",
    "print (\"df_4\",df_4.shape)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(df_4)\n",
    "data = scaler.transform(df_4)\n",
    "print (\"data\",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num pca_comps per > 0.8 ratio: 10 0.830338526276\n",
      "Explained variance first 2 components 0.363467840098\n",
      "46\n",
      "0.363467840098\n",
      "PCA+K-means: 10\n",
      "1st component:  [ -1.89572397e-01   4.41434607e-04   8.44247410e-03   8.58181762e-03\n",
      "  -3.91873299e-04  -5.79638084e-02  -2.48596604e-02  -2.68902811e-03\n",
      "  -4.99611076e-02  -1.65442429e-03  -1.11014642e-03  -6.31297316e-03\n",
      "  -1.83675923e-02  -8.42751841e-03  -8.71409706e-02  -5.62286682e-02\n",
      "  -4.27384890e-03  -2.21961853e-03  -4.26942169e-07  -1.31101970e-02\n",
      "  -0.00000000e+00  -3.00301905e-02  -2.31132688e-02  -1.32779353e-04\n",
      "  -2.31344976e-02  -2.05341821e-02  -1.17861274e-03  -3.71459660e-05\n",
      "  -6.86118893e-05  -1.99005040e-05  -0.00000000e+00  -0.00000000e+00\n",
      "  -3.19869827e-02  -1.64859889e-03  -8.82342656e-05  -3.51866950e-05\n",
      "  -0.00000000e+00  -0.00000000e+00  -7.85732021e-01  -5.68525879e-01\n",
      "  -1.86860891e-03  -2.83196569e-02  -6.06175026e-04  -2.06771276e-03\n",
      "   3.37107324e-04  -3.47340451e-02]\n",
      "2nd component:  [  9.55563811e-01  -1.42133698e-02   1.82174802e-02   3.14100327e-02\n",
      "  -3.13667368e-04   2.26864548e-02   1.20159511e-02  -5.09214908e-02\n",
      "   6.25340826e-04   5.16552590e-03   2.18225418e-03   2.65902228e-02\n",
      "   3.79938844e-02   7.66448502e-03  -4.26896430e-02  -2.42255054e-02\n",
      "   7.74669865e-04  -1.77709988e-04   4.07975777e-05  -3.12002983e-03\n",
      "  -0.00000000e+00  -4.55957056e-03  -6.00656037e-03  -3.98672936e-05\n",
      "  -4.42360974e-03  -3.66878043e-03   1.59698655e-04  -4.74226410e-05\n",
      "   7.76846827e-06  -1.43929111e-04  -0.00000000e+00  -0.00000000e+00\n",
      "  -2.15051390e-02  -3.91065697e-04   8.65907722e-07   2.96893780e-05\n",
      "  -0.00000000e+00  -0.00000000e+00  -1.66288212e-01  -9.58132601e-02\n",
      "  -1.38228648e-02   1.74478928e-01  -4.13742920e-03  -1.53455730e-02\n",
      "  -9.53656449e-04   9.58767561e-02]\n"
     ]
    }
   ],
   "source": [
    "#### Feat sel with pca(0.8, 0.9) explained var \n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "newdata, newdata_test = data[msk].copy(), data[~msk].copy()\n",
    "\n",
    "data=newdata\n",
    "\n",
    "thrd = 0.8\n",
    "total = 0\n",
    "pca = PCA().fit(data)\n",
    "reduced_data = pca.transform(data)\n",
    "for pca_comps,r in enumerate(pca.explained_variance_ratio_):\n",
    "    if total > thrd:\n",
    "        break\n",
    "    total += r\n",
    "print (\"Num pca_comps per >\", thrd,\"ratio:\", pca_comps, total)\n",
    "print (\"Explained variance first 2 components\",pca.explained_variance_ratio_[0]+pca.explained_variance_ratio_[1])\n",
    "print (pca.n_components_)\n",
    "print (np.sum(pca.explained_variance_ratio_[:2]))\n",
    "\n",
    "print (\"PCA+K-means:\", pca_comps)\n",
    "print(\"1st component: \", pca.components_[0])\n",
    "print(\"2nd component: \", pca.components_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2  the average metrics.calinski_harabaz_score is : 19075.0891961\n",
      "For n_clusters = 3  the average metrics.calinski_harabaz_score is : 15976.925097\n",
      "For n_clusters = 4  the average metrics.calinski_harabaz_score is : 15374.7166123\n",
      "For n_clusters = 5  the average metrics.calinski_harabaz_score is : 14534.8386394\n",
      "For n_clusters = 6  the average metrics.calinski_harabaz_score is : 13705.2309607\n",
      "For n_clusters = 7  the average metrics.calinski_harabaz_score is : 12386.2951561\n",
      "For n_clusters = 8  the average metrics.calinski_harabaz_score is : 12588.1401003\n",
      "For n_clusters = 9  the average metrics.calinski_harabaz_score is : 11716.0870499\n",
      "For n_clusters = 10  the average metrics.calinski_harabaz_score is : 11394.2008998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11aa48d0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "Resultk=[0]*9\n",
    "ResultC=[0]*9\n",
    "for k in [2,3,4,5,6,7,8,9,10]:\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(reduced_data[:,:pca_comps])\n",
    "    #cluster_labels=kmeans.fit(reduced_data[:,:2])\n",
    "    #silhouette_avg = silhouette_score(reduced_data[:,:pca_comps], cluster_labels)\n",
    "    #silhouette_avg = silhouette_score(reduced_data[:,:2], cluster_labels)\n",
    "    #print(\"For n_clusters =\", k, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    calinski_harabaz_score_avg = metrics.calinski_harabaz_score(reduced_data[:,:pca_comps], cluster_labels)\n",
    "    #calinski_harabaz_score_avg = metrics.calinski_harabaz_score(reduced_data[:,:2], cluster_labels)\n",
    "    print(\"For n_clusters =\", k,\" the average metrics.calinski_harabaz_score is :\", calinski_harabaz_score_avg)\n",
    "    Resultk[k-2]=k\n",
    "    ResultC[k-2]=calinski_harabaz_score_avg    \n",
    "plt.plot(Resultk,ResultC,'r*-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "pca = PCA().fit(data)\n",
    "cluster_labels = kmeans.fit_predict(reduced_data[:,:2])\n",
    "plt.figure()\n",
    "plt.plot(range(len(pca.explained_variance_ratio_)), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.axvline(pca_comps, color=\"red\")  \n",
    "plt.ylim(0.0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 46)\n",
      "(101766, 46)\n",
      "(101766, 46)\n"
     ]
    }
   ],
   "source": [
    "n_clusters=2\n",
    "reduced_data = pca.transform(data)\n",
    "#print (\"Reduced data: \",reduced_data.shape)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(reduced_data[:,:2])\n",
    "\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min()-.05, reduced_data[:, 0].max()+.05\n",
    "y_min, y_max = reduced_data[:, 1].min()-.05, reduced_data[:, 1].max()+.05\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(10,10))\n",
    "#plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap= plt.cm.Pastel2,#cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "#plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=4)\n",
    "print(df_4.shape)\n",
    "print(data.shape)\n",
    "print(reduced_data.shape)\n",
    "\"\"\"\n",
    "listA=df_3[df_3['readmitted'] == 0].index\n",
    "plt.plot(reduced_data[listA, 0], reduced_data[listA, 1],'k.', markersize=4, c='g', label='No Readmitted')\n",
    "listB=df_3[df_3['readmitted'] == 29].index\n",
    "plt.plot(reduced_data[listB, 0],reduced_data[listB, 1],'k.', markersize=4, c='r',label ='<30')\n",
    "listC=df_3[df_3['readmitted'] == 31].index\n",
    "plt.plot(reduced_data[listC, 0],reduced_data[listC, 1],'k.', markersize=4, c='b',label ='>30')\n",
    "\"\"\"\n",
    "listA=df[df['change'] == 0].index\n",
    "plt.plot(reduced_data[listA, 0], reduced_data[listA, 1],'k.', markersize=4, c='g', label='No disease')\n",
    "listB=df[df['change'] == 1].index\n",
    "plt.plot(reduced_data[listB, 0],reduced_data[listB, 1],'k.', markersize=4, c='r',label ='Disease')\n",
    "\n",
    "#Peripheral_vascular_disease', 'Cerebrovascular_disease', 'Dementia',\n",
    "#       'Chronic_pulmonary_disease', 'Myocardial_infarction',\n",
    "#       'Congestive_heart_failure'\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[0, 0], centroids[0, 1],\n",
    "            marker='>', s=169, linewidths=3, \n",
    "            color='black', zorder=10)\n",
    "plt.scatter(centroids[1, 0], centroids[1, 1],\n",
    "            marker='H', s=169, linewidths=3, \n",
    "            color='black', zorder=10)\n",
    "\"\"\"\n",
    "plt.scatter(centroids[2, 0], centroids[2, 1],\n",
    "            marker='>', s=169, linewidths=3, \n",
    "            color='blue', zorder=10)\n",
    "plt.scatter(centroids[3, 0], centroids[3, 1],\n",
    "            marker='H', s=169, linewidths=3, \n",
    "            color='blue', zorder=10)\n",
    "plt.scatter(centroids[4, 0], centroids[4, 1],\n",
    "            marker='>', s=169, linewidths=3, \n",
    "            color='purple', zorder=10)\n",
    "plt.scatter(centroids[5, 0], centroids[5, 1],\n",
    "            marker='H', s=169, linewidths=3, \n",
    "            color='purple', zorder=10)\n",
    "            \"\"\"\n",
    "plt.title('K-means clustering on the diabetes dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_diabetes =  [44754, 52231]\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_Peripheral_vascular_disease =  [46112, 53739]\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_Cerebrovascular_disease =  [44356, 51841]\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_Dementia =  [46929, 54626]\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_Chronic_pulmonary_disease =  [40249, 47877]\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_Congestive_heart_failure =  [38843, 45459]\n",
      "cluster_sizes =  [47011, 54755]\n",
      "num_no_readmitted =  [24181, 30683]\n",
      "average age =  [70.347365510199737, 71.499041183453571]\n",
      "average weight =  [92.633991118134659, 92.56197975410717]\n",
      "average A1Cresult =  [0.60211439875773753, -0.066185736462423525]\n"
     ]
    }
   ],
   "source": [
    "n_clusters=2\n",
    "print(set(cluster_labels))\n",
    "num_Myocardial_infarction = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Myocardial_infarction\")] == 0):\n",
    "        num_Myocardial_infarction[cluster_labels[i]] = num_Myocardial_infarction[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_diabetes = \", num_Myocardial_infarction)\n",
    "\n",
    "num_Peripheral_vascular_disease = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Peripheral_vascular_disease\")] == 0):\n",
    "        num_Peripheral_vascular_disease[cluster_labels[i]] = num_Peripheral_vascular_disease[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Peripheral_vascular_disease = \", num_Peripheral_vascular_disease)\n",
    "\n",
    "num_Cerebrovascular_disease = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Cerebrovascular_disease\")] == 0):\n",
    "        num_Cerebrovascular_disease[cluster_labels[i]] = num_Cerebrovascular_disease[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Cerebrovascular_disease = \", num_Cerebrovascular_disease)\n",
    "\n",
    "num_Dementia = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Dementia\")] == 0):\n",
    "        num_Dementia[cluster_labels[i]] = num_Dementia[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Dementia = \", num_Dementia)\n",
    "\n",
    "num_Chronic_pulmonary_disease = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Chronic_pulmonary_disease\")] == 0):\n",
    "        num_Chronic_pulmonary_disease[cluster_labels[i]] = num_Chronic_pulmonary_disease[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Chronic_pulmonary_disease = \", num_Chronic_pulmonary_disease)\n",
    "\n",
    "num_Congestive_heart_failure = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"Congestive_heart_failure\")] == 0):\n",
    "        num_Congestive_heart_failure[cluster_labels[i]] = num_Congestive_heart_failure[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_Congestive_heart_failure = \", num_Congestive_heart_failure)\n",
    "\n",
    "num_readmitted = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "    if (data[i][df_3.columns.get_loc(\"readmitted\")] == 0):\n",
    "        num_readmitted[cluster_labels[i]] = num_readmitted[cluster_labels[i]] + 1\n",
    "print (\"cluster_sizes = \", [ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ])\n",
    "print (\"num_no_readmitted = \", num_readmitted)\n",
    "\n",
    "num_age = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "        num_age[cluster_labels[i]] = num_age[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(\"age\")]\n",
    "mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "print (\"average age = \", list(map(truediv,num_age,mida_cluster)))\n",
    "\n",
    "num_age = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "        num_age[cluster_labels[i]] = num_age[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(\"weight\")]\n",
    "mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "print (\"average weight = \", list(map(truediv,num_age,mida_cluster)))\n",
    "\n",
    "num_age = [0] * n_clusters\n",
    "for i in range(len(reduced_data[:,:2])):\n",
    "        num_age[cluster_labels[i]] = num_age[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(\"A1Cresult\")]\n",
    "mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "print (\"average A1Cresult = \", list(map(truediv,num_age,mida_cluster)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20458, 49)\n",
      "(81308, 49)\n",
      "Confusion matrix, without normalization\n",
      "[[10992     0]\n",
      " [    0  9466]]\n",
      "Normalized confusion matrix\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "Accuracy score 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   cluster0       1.00      1.00      1.00     10992\n",
      "   cluster1       1.00      1.00      1.00      9466\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20458\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'min_samples_leaf': 5, 'max_leaf_nodes': 5, 'max_depth': None, 'criterion': 'gini', 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "print(newdata_test.shape)\n",
    "print(newdata.shape)\n",
    "pca_test = PCA().fit(newdata_test)\n",
    "reduced_data_test = pca_test.transform(newdata_test)\n",
    "pca = PCA().fit(newdata)\n",
    "reduced_data = pca_test.transform(newdata)\n",
    "n_clusters=2\n",
    "pca_comps=11\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(reduced_data[:,:pca_comps])\n",
    "y_train=kmeans.labels_\n",
    "y_test=kmeans.predict(reduced_data_test[:,:pca_comps])\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "#              \"min_samples_split\": [2, 10, 20],\n",
    "#              \"max_depth\": [None, 2, 5, 10],\n",
    "#              \"min_samples_leaf\": [1, 5, 10],\n",
    "#              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "#              }\n",
    "\n",
    "param_grid = {\"criterion\": [\"gini\"],\n",
    "              \"min_samples_split\": [2],\n",
    "              \"max_depth\": [None],\n",
    "              \"min_samples_leaf\": [5],\n",
    "              \"max_leaf_nodes\": [5],\n",
    "              }\n",
    "\n",
    "tree2 = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid)\n",
    "\n",
    "tree2.fit(reduced_data, y_train)\n",
    "y_pred = tree2.predict(reduced_data_test)\n",
    "\n",
    "#max_depth=4\n",
    "#clf = tree.DecisionTreeClassifier(random_state=13)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, kmeans.labels_, test_size=0.2)\n",
    "#y_pred = clf.fit(df_4, y_train).predict(df_4_test)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names=['cluster0','cluster1']\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score\", accuracy_score(y_test, y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(tree2.best_params_)\n",
    "    \n",
    "with open(\"C://Users/laia.subirats/Documents/output_diabetes.dot\", \"w\") as output_file:\n",
    "    tree.export_graphviz(tree2.best_estimator_, out_file=output_file, feature_names=df_3.columns.tolist(),class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetesMed :  [1.0, 0.57258697835814076] , p-value:  0.0\n",
      "change :  [1.0, 0.0] , p-value:  0.0\n",
      "rosiglitazone :  [0.11193125013294761, 0.018628435759291389] , p-value:  0.0\n",
      "num_medications :  [18.187041330752376, 14.162870970687608] , p-value:  0.0\n",
      "pioglitazone :  [0.12590670268660525, 0.023541229111496666] , p-value:  0.0\n",
      "glyburide :  [0.14477462721490714, 0.054132042735823213] , p-value:  0.0\n",
      "glipizide :  [0.17574610197613325, 0.064176787507990135] , p-value:  0.0\n",
      "metformin :  [0.32135032226500182, 0.077125376677928958] , p-value:  0.0\n",
      "glimepiride :  [0.078598625853523646, 0.022664596840471191] , p-value:  1.90455413404e-272\n",
      "time_in_hospital :  [4.7476973474293249, 4.0940188110674827] , p-value:  2.51073752735e-267\n",
      "A1Cresult :  [0.60211439875773753, -0.066185736462423525] , p-value:  3.84976743072e-255\n",
      "repaglinide :  [0.02454744634234541, 0.0065747420326910787] , p-value:  1.91641224807e-93\n",
      "num_lab_procedures :  [44.45365978175321, 41.929686786594829] , p-value:  1.02804773373e-92\n",
      "number_diagnoses :  [7.533428346557189, 7.3274586795726417] , p-value:  1.82431729978e-64\n",
      "nateglinide :  [0.011614303035459786, 0.0027029495023285547] , p-value:  2.34463354246e-57\n",
      "readmitted :  [14.81810640062964, 13.416747329011049] , p-value:  1.36862130488e-48\n",
      "acarbose :  [0.0057858799004488308, 0.00067573737558213867] , p-value:  3.44911131254e-44\n",
      "glyburide-metformin :  [0.010571993788687754, 0.0036343712902931241] , p-value:  3.65325428336e-38\n",
      "number_emergency :  [0.2368169151900619, 0.16436855081727697] , p-value:  3.0408645242e-35\n",
      "age :  [70.347365510199737, 71.499041183453571] , p-value:  1.41587815478e-30\n",
      "max_glu_serum :  [7.2387951755972004, 4.4712446351931332] , p-value:  7.1464159416e-27\n",
      "Chronic_pulmonary_disease :  [0.14383867605454043, 0.12561409916902566] , p-value:  1.75303065102e-17\n",
      "number_outpatient :  [0.40326732041437108, 0.34024290019176329] , p-value:  2.55933726756e-15\n",
      "number_inpatient :  [0.66833294335368321, 0.60743311113140352] , p-value:  1.71187106378e-14\n",
      "gender :  [0.52953564059475444, 0.54444342982376037] , p-value:  1.98458064045e-06\n",
      "insulin :  [0.27193635532109506, 0.29697744498219342] , p-value:  0.000199867557443\n",
      "glipizide-metformin :  [0.00023398779009168067, 3.652634462606155e-05] , p-value:  0.00545648063341\n",
      "weight :  [92.633991118134659, 92.56197975410717] , p-value:  0.0111548809155\n",
      "Cerebrovascular_disease :  [0.056476143881219291, 0.053218884120171672] , p-value:  0.0227445551557\n",
      "Dementia :  [0.0017442726170470741, 0.0023559492283809699] , p-value:  0.0324629034297\n"
     ]
    }
   ],
   "source": [
    "#P-values of attributes of each cluster\n",
    "import scipy.stats as stats\n",
    "#true_mu = 0\n",
    "listaA=df_3.columns.tolist()\n",
    "cluster1=df_4[kmeans.labels_==0]\n",
    "cluster2=df_4[kmeans.labels_==1]\n",
    "cluster_labels=kmeans.labels_\n",
    "#print(cluster1.shape)\n",
    "#print(cluster2.shape)\n",
    "contador=0\n",
    "for z in range(0,len(df_3.columns.tolist())):\n",
    "    two_sample = stats.ttest_ind(cluster1[:,z],cluster2[:,z])\n",
    "    if(two_sample[1]<0.05):contador=contador+1\n",
    "\n",
    "w, h = 3, contador\n",
    "Matrix = [[0.0 for x in range(w)] for y in range(h)] \n",
    "i=0\n",
    "for z in range(0,len(df_3.columns.tolist())):\n",
    "    #print(df_2.loc[1,z])\n",
    "    #print(np.std(cluster1[:,z]))\n",
    "    #print(df_2.values[:,z])\n",
    "    two_sample = stats.ttest_ind(cluster1[:,z],cluster2[:,z])\n",
    "    #two_sample = stats.chisquare(cluster1[:,8],cluster2[:,8])\n",
    "    if(two_sample[1]<0.05): \n",
    "        #print(i)\n",
    "        Matrix[i][0]=listaA[z]\n",
    "        Matrix[i][1]='{0:.400f}'.format(two_sample[1])\n",
    "        Matrix[i][2]=two_sample[1]\n",
    "        i=i+1\n",
    "arr = np.array(Matrix)\n",
    "arr = arr[arr[:,1].argsort()]\n",
    "#print(arr)\n",
    "\n",
    "for z in range(0,h):\n",
    "    if (0<1):\n",
    "        num_hipertensos = [0] * n_clusters\n",
    "        for i in range(len(data[:,:2])):\n",
    "            num_hipertensos[cluster_labels[i]] = num_hipertensos[cluster_labels[i]] + df_4[i][df_3.columns.get_loc(arr[z,0])]\n",
    "        mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "        print ((arr[z,0]),\": \", list(map(truediv,num_hipertensos,mida_cluster)),\", p-value: \",arr[z,2])\n",
    "    else:\n",
    "        num_hipertensos = [0] * n_clusters\n",
    "        for i in range(len(data[:,:2])):\n",
    "            #print(\"z\",z)\n",
    "            #print(\"i\",i)\n",
    "            if (data[i][df_3.columns.get_loc(arr[z,0])] == 1):\n",
    "                num_hipertensos[cluster_labels[i]] = num_hipertensos[cluster_labels[i]] + 1\n",
    "        mida_cluster=[ len([1 for label in cluster_labels if label == i]) for i in range(n_clusters) ]\n",
    "        percentage=list(map(truediv,num_hipertensos,mida_cluster))\n",
    "        percentage[0]=round(percentage[0],2)\n",
    "        percentage[1]=round(percentage[1],2)\n",
    "        print ((arr[z,0]),\": \", num_hipertensos,\", percentage: \",percentage, \"p-value: \",arr[z,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12932, 46)\n",
      "(52197, 46)\n",
      "ytrain:  (52197,)\n",
      "xtrain:  (52197, 45)\n",
      "y_test:  (12932,)\n",
      "x_test:  (12932, 45)\n",
      "{'0.00', '1.00', '0.94'}\n",
      "{'0.00', '1.00', '0.94'}\n",
      "Confusion matrix, without normalization\n",
      "[[6418    0  557]\n",
      " [ 994    0  430]\n",
      " [3644    0  889]]\n",
      "Normalized confusion matrix\n",
      "[[ 0.92  0.    0.08]\n",
      " [ 0.7   0.    0.3 ]\n",
      " [ 0.8   0.    0.2 ]]\n",
      "Accuracy score 0.565032477575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.92      0.71      6975\n",
      "        <30       0.00      0.00      0.00      1424\n",
      "        >30       0.47      0.20      0.28      4533\n",
      "\n",
      "avg / total       0.48      0.57      0.48     12932\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'min_samples_leaf': 5, 'max_depth': None, 'criterion': 'gini', 'max_leaf_nodes': 5, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Decision tree to predict readmissions\n",
    "print(newdata_test.shape)\n",
    "print(newdata.shape)\n",
    "\n",
    "\n",
    "y_train=newdata[:,0]\n",
    "print(\"ytrain: \",y_train.shape)\n",
    "x_train=newdata[:,1:]\n",
    "print(\"xtrain: \",x_train.shape)\n",
    "y_test=newdata_test[:,0]\n",
    "print(\"y_test: \",y_test.shape)\n",
    "x_test=newdata_test[:,1:]\n",
    "print(\"x_test: \",x_test.shape)\n",
    "\n",
    "y_train_encoded= np.array([\"%.2f\" % w for w in y_train.reshape(y_train.size)])\n",
    "y_train_encoded = y_train_encoded.reshape(y_train.shape)\n",
    "y_train_encoded=y_train_encoded.tolist()\n",
    "#print(\"ytrain_encoded\", y_train_encoded)\n",
    "print(set(y_train_encoded))\n",
    "y_test_encoded= np.array([\"%.2f\" % w for w in y_test.reshape(y_test.size)])\n",
    "y_test_encoded = y_test_encoded.reshape(y_test.shape)\n",
    "y_test_encoded=y_test_encoded.tolist()\n",
    "#print(\"ytrain_encoded\", y_train_encoded)\n",
    "print(set(y_test_encoded))\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "#              \"min_samples_split\": [2, 10, 20],\n",
    "#              \"max_depth\": [None, 2, 5, 10],\n",
    "#              \"min_samples_leaf\": [1, 5, 10],\n",
    "#              \"max_leaf_nodes\": [None, 5, 10, 20],\n",
    "#              }\n",
    "\n",
    "param_grid = {\"criterion\": [\"gini\"],\n",
    "              \"min_samples_split\": [2],\n",
    "              \"max_depth\": [None],\n",
    "              \"min_samples_leaf\": [5],\n",
    "              \"max_leaf_nodes\": [5],\n",
    "              }\n",
    "\n",
    "tree2 = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid)\n",
    "\n",
    "tree2.fit(x_train, y_train_encoded)\n",
    "y_pred = tree2.predict(x_test)\n",
    "\n",
    "#max_depth=4\n",
    "#clf = tree.DecisionTreeClassifier(random_state=13)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, kmeans.labels_, test_size=0.2)\n",
    "#y_pred = clf.fit(df_4, y_train).predict(df_4_test)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_encoded, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names=['0','<30','>30']\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score\", accuracy_score(y_test_encoded, y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=class_names))\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(tree2.best_params_)\n",
    "    \n",
    "with open(\"C://Users/laia.subirats/Documents/output_diabetes.dot\", \"w\") as output_file:\n",
    "    tree.export_graphviz(tree2.best_estimator_, out_file=output_file, feature_names=df_3.columns.tolist(),class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.349 (+/-0.032) for {'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       0.00       0.56      0.98      0.71      6975\n",
      "       0.94       0.00      0.00      0.00      1424\n",
      "       1.00       0.49      0.07      0.12      4533\n",
      "\n",
      "avg / total       0.47      0.55      0.42     12932\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.348 (+/-0.008) for {'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       0.00       0.56      0.98      0.71      6975\n",
      "       0.94       0.00      0.00      0.00      1424\n",
      "       1.00       0.49      0.07      0.12      4533\n",
      "\n",
      "avg / total       0.47      0.55      0.42     12932\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laia.subirats\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                     'C': [1, 10, 100, 1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'],\n",
    "                     'C': [1]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=10,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(x_train, y_train_encoded)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    #y_train, y_pred = y_test, clf.predict(x_test)\n",
    "    y_train2, y_pred = y_test_encoded, clf.predict(x_test)\n",
    "    print(classification_report(y_train2, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
